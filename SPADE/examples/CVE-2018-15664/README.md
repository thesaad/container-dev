## CVE-2018-15664 ##
## Symlink Swap to get root acces ##

In this CVE, a function called FollowSymlinkInScope(), used by docker daemon, is vulnerable to TOCTOU(Time To Check To Time Of Use) race attack. When a user tries to copy something into the container filesystem using docker cp, the docker daemon process executes FollowSymlinkInScope() function. This function resolves the path as if the process was inside the container. Once an actual non-symlink path is found, the docker copy command adds this resolved path to the container mount point, and then simply copies. But, an attacker can use the time window after the path resolution and right before the write operation to create a symlink that will be resolved on the host root directory. Through this exploit, the docker process could potentially overwrite any file on the host due to changes inside the container. A detailed explaination can be found at: https://medium.com/@cpuguy83/docker-symlink-traversal-cve-2018-15664-explained-6bcc715d0a5a


The flow can be re iterated through SPADE's audit reporter. Before that. disp_qos property should be set to lossless under /etc/audit/auditd.conf. And before running the run.sh. SPADE should be started and reporter Audit should be added. 

To that end, there is a simple program provided, the SPADE log for the SPADE run, the Audit log for the program (in skype channel), and the DOT graph for the program. Files with the extension `.gz` can be uncompressed using the command `gunzip <name of the file>`.

## Program ##

The `program` directory contains the the scripts to re-iterate the process. setup.sh sets up the required docker version and then builds the docker image by invoking scrip run_write.sh. run.script starts docker container by passing the targetted to container, container uses symlink_swap binary which keeps on renaming the symlink of the target path and a stashed path inside container, dockerd here resolves the symlinks and if race condition is won by the container's renaming process, the target path is exposed to as container's file system because while resolving symlinks, dockerd uses chroot to make that resolved directory as container's file system. The SymlinkSwap directory contains the Dockerfil and the program which usese syscall to rename symlink path to the stashed path.

* 1- Build: `./setup.sh`
* 2- Start Spade using `./spade start` //the spade should be started as different user while collecting Audit Provenance.
* 3- go to spade control using `./spade control` and add reporter in Spade using `add reporter Audit outputLog=/tmp/audit.log fileIO=true netIO=true`
* 4- start docker using `sudo systemctl start docker` //this will resolve our -1 Namespace set for the processes interacting with targets
* 5- restart nautilus using `nautilus -q && nautil &` //for same purpose as step 4.
* 6- Run script: `./run.sh`

once the Run script is completed, the logs will be captured and saved at path '/tmp/audit.log'. We need to save it some where but before make sure all data in buffers logged. To check, one can create a dump file some where and grep in Audit.log if that specific files is created. After that, remove reporter using `remove reporter Audit` and then copy /tmp/audit.log to some other path so that it doesn't lost after restart. Second step is to load these logs in spade again and run queries to export the said graph. Follow these steps to proceed with that.

* 1- Start spade if it's no running already. using `./spade start` 
* 2- go to spade control using `./spade control` and add storage to spade using `add storage PostgreSQL database=spadedb` // before doing this, PostgreSQL must be installed using script 'installPostgres.sh' available under SPADE/bin directory. 
* 3- Add reporter in spade using `add reporter Audit inputLog=/tmp/audit.log fileIO=true netIO=true` //this is the log we capture in our first part of the experiment

wait until all data is copied to postgres. this can be checked using pgAdmin for Postgres. After that, 

* 4- Add analyzer to be run queries using `add analyzer CommandLine`. 
* 5- Exit from spade control using `exit`
* 6- bash into spade query using `./spade query`. a similar to spade control shell will appear. 
* 7- Use query from the query folder using command `load <path to query file>`. This may take some time depending on the matches
* 8- This will export a file named as pathT.dot. Use `dot -Tsvg -o out.svg pathT.dot` to export graph in SVG. Which can then be visualized using chrom or firefox

## SPADE Log ##

The file `SPADE_09.14.2021-1.38.15.tar.xz` is a SPADE log (compressed) file which contains the result of detecting crossnaespaces events while spade run. The intial list of crossname space events can be printed using (after extracting):

`grep 'CrossNamespaces event' SPADE_09.14.2021-1.38.15.log`

For our scenario, we used inode of the target file `w00t_w00t_im_a_flag`. Which were multiple and the required one we ended up is: 232380. So the final grep will be. 

`grep 'CrossNamespaces event' SPADE_09.14.2021-1.38.15.log | grep 'inode=232380'`

Using this command, the crossnamespace events will be printed having readers and writers processes along with their namespace ids. 

## query ##
query directory contains the query which was used to export the graph. It's a very simple query in which the same constraints retreived via CrossNamespace event from Spade Log. First three lines of query are simply constraints of an event associated to this specific inode. Which is inode, reader/writer process namespace set identifiers. Line 5-7 reterive vertices based on the relevant conditions specified for inode/reader/writers. Line 9 fetches paths from readers to inode using `$base.getPath($readerVertices, $inodes, 1)` and from inode to writers ` $base.getPath($inodes, $writerVertices, 1)`, then combine the graph using '+' operator and store a new variable called paths. In line 10, the size of the graph is reduced by collapsing edges based on the annotation 'type'. Till now, the graph we get which is disconnected, can be seen in graph directory and explain in "Graph" seciton below. To merge the graph, a Transformer is written named as 'MergeVertex' which actually merges all vertices based on given keys if the values is same. The line 11 in query actually does this task. it passes Transformer name and 'inode' as key so that it merges all vertices whose inode is same. 

## Transformer ##
Transformer folder contains the Transformer which is used in query to merge vertices of having same inode. To use this transofer, this file should be placed under SPADE/srce/spade/transformer directory and spade should be rebuild using commands `./configure` and `make` under it's root directory. 

## Graph ##

The file `15664-graph.dot` and `15664-graph.svg` under `graph` directory are the same version with different file types, it shows the disconnected graph and shows there is one inode '232380' which is being accessed by process of different name spaces. There are multiple indoes because the paths are different (symlink paths are tackled as different files in Audit). But because the file is actually same, we can merge and rename it to a single vertex by combining all vertices where inode is same.  `15664-graph-transformed.svg` is the combied version of the graph where the inode similar vertices are merged into one signle vertex. The other information is merged using ',' (comma) and can be seen in the vertex. 

## Audit Log ##

shared in skype channel using commit hash. 
